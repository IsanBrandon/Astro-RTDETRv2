##### runtime #####
print_freq: 100
output_dir: '/home/uvll/Desktop/hyuk/rtdetrv2_pytorch/output/rtdetrv2_r50vd_dsg'
checkpoint_freq: 10

sync_bn: True
find_unused_parameters: False

use_amp: True
use_ema: True
ema:
  type: ModelEMA
  decay: 0.9999
  warmups: 2000

scaler:
  type: GradScaler
  enabled: True

##### task / model #####
task: detection

model: RTDETR
criterion: RTDETRCriterionv2
postprocessor: RTDETRPostProcessor
use_focal_loss: True
eval_spatial_size: [640, 640]   # h w

RTDETR:
  backbone: PResNet
  encoder: HybridEncoder
  decoder: RTDETRTransformerv2

PResNet:
  depth: 50
  variant: d
  freeze_at: 0
  return_idx: [1, 2, 3]
  num_stages: 4
  freeze_norm: True
  pretrained: True

HybridEncoder:
  in_channels: [512, 1024, 2048]
  feat_strides: [8, 16, 32]
  # intra
  hidden_dim: 256
  use_encoder_idx: [2]
  num_encoder_layers: 1
  nhead: 8
  dim_feedforward: 1024
  dropout: 0.
  enc_act: 'gelu'
  # cross
  expansion: 1.0
  depth_mult: 1
  act: 'silu'

RTDETRTransformerv2:
  feat_channels: [256, 256, 256]
  feat_strides: [8, 16, 32]
  hidden_dim: 256
  num_levels: 3
  num_layers: 6
  num_queries: 300
  num_denoising: 100
  label_noise_ratio: 0.5
  box_noise_scale: 1.0
  eval_idx: -1
  # NEW
  num_points: [4, 4, 4]
  cross_attn_method: default      # default, discrete
  query_select_method: default    # default, agnostic

RTDETRPostProcessor:
  num_top_queries: 300

RTDETRCriterionv2:
  weight_dict: {loss_vfl: 1, loss_bbox: 5, loss_giou: 2}
  losses: ['vfl', 'boxes']
  alpha: 0.75
  gamma: 2.0
  matcher:
    type: HungarianMatcher
    weight_dict: {cost_class: 2, cost_bbox: 5, cost_giou: 2}
    alpha: 0.25
    gamma: 2.0

##### optim / sched #####
epoches: 200
clip_max_norm: 0.1

optimizer:
  type: AdamW
  params:
    - { params: '^(?=.*backbone)(?!.*norm).*$', lr: 0.00001 }
    - { params: '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$', weight_decay: 0. }
  lr: 0.0001
  betas: [0.9, 0.999]
  weight_decay: 0.0001

lr_scheduler:
  type: MultiStepLR
  milestones: [1000]
  gamma: 0.1

lr_warmup_scheduler:
  type: LinearWarmup
  warmup_duration: 2000

##### evaluator / dataset (COCO-format DSG) #####
evaluator:
  type: CocoEvaluator
  iou_types: ['bbox']

num_classes: 2
remap_mscoco_category: False   # <-- 커스텀 2클래스이므로 False 권장

##### dataloader #####
train_dataloader:
  type: DataLoader
  dataset:
    type: CocoDetection
    img_folder: /home/uvll/Desktop/hyuk/rtdetrv2_pytorch/dataset/Dsg/train2017
    ann_file: /home/uvll/Desktop/hyuk/rtdetrv2_pytorch/dataset/Dsg/annotations/train_labels.json
    return_masks: False
    transforms:
      type: Compose
      ops:
        - {type: RandomPhotometricDistort, p: 0.5}
        - {type: RandomZoomOut, fill: 0}
        - {type: RandomIoUCrop, p: 0.4}          # 소형 객체 보호 위해 p 조정
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: RandomHorizontalFlip}
        - {type: Resize, size: [640, 640]}
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
        - {type: ConvertBoxes, fmt: 'cxcywh', normalize: True}
  shuffle: True
  num_workers: 4
  drop_last: True
  total_batch_size: 8
  collate_fn:
    type: BatchImageCollateFuncion
    scales: [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800]
    stop_epoch: 71

val_dataloader:
  type: DataLoader
  dataset:
    type: CocoDetection
    img_folder: /home/uvll/Desktop/hyuk/rtdetrv2_pytorch/dataset/Dsg/val2017
    ann_file: /home/uvll/Desktop/hyuk/rtdetrv2_pytorch/dataset/Dsg/annotations/val_labels.json
    return_masks: False
    transforms:
      type: Compose
      ops:
        - {type: Resize, size: [640, 640]}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
  shuffle: False
  num_workers: 4
  drop_last: False
  total_batch_size: 16
  collate_fn:
    type: BatchImageCollateFuncion
